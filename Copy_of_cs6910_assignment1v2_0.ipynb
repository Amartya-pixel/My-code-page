{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amartya-pixel/My-code-page/blob/master/Copy_of_cs6910_assignment1v2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38Elf0RQLsQp",
        "outputId": "c5b1a423-a363-4c3e-c838-f8593de8538c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.10-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |▋                               | 30 kB 18.3 MB/s eta 0:00:01\r\u001b[K     |▊                               | 40 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 71 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 81 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 92 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 102 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 112 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 122 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 133 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 143 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 153 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 163 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 174 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 184 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 194 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 204 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 215 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 225 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 235 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 245 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 256 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████                           | 266 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 276 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 286 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 296 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 307 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 317 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 327 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 337 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 348 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 358 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 368 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 378 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 389 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 399 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 409 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 419 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 430 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 440 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 450 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 460 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 471 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 481 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 491 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 501 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 512 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 522 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 532 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 542 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 552 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 563 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 573 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 583 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 593 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 604 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 614 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 624 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 634 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 645 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 655 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 665 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 675 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 686 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 696 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 706 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 716 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 727 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 737 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 747 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 757 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 768 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 778 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 788 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 798 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 808 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 819 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 829 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 839 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 849 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 860 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 870 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 880 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 890 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 901 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 911 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 921 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 931 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 942 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 952 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 962 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 972 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 983 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 993 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.0 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.0 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.0 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.0 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.0 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.1 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.1 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.1 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.1 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.1 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.1 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.1 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.1 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.1 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.2 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.2 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.2 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.2 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.2 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.2 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.2 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.2 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.3 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.3 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.3 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.3 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.3 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.3 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.3 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.3 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.4 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.4 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.4 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.4 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.4 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.4 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.4 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.4 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.4 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.4 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.5 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.5 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.5 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.5 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.5 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.5 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.5 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.5 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.5 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.5 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.6 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.6 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.6 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.6 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.6 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.6 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.6 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.6 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.6 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.6 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.7 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.7 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.7 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.7 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.7 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.7 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7 MB 12.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Collecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.6-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 48.0 MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 38.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=83705315d1a5f6079866f631a223f2b89422f021900b55695f94e3aa1c736f19\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, yaspin, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.6 shortuuid-1.0.8 smmap-5.0.0 wandb-0.12.10 yaspin-2.1.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb\n",
        "!wandb login "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVoYf90qUPHo"
      },
      "outputs": [],
      "source": [
        "#importing required packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"CS6910 ASSIGNMENT 1\", entity=\"dlstack\", name=\"Assignment 1 Dataset Classes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "LBY2zld8ZYd8",
        "outputId": "87ff019a-9235-49ed-bb18-c4b603ceb04f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdlstack\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/dlstack/CS6910%20ASSIGNMENT%201/runs/1vlj1zdx\" target=\"_blank\">Assignment 1 Dataset Classes</a></strong> to <a href=\"https://wandb.ai/dlstack/CS6910%20ASSIGNMENT%201\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f03f2f8ba50>"
            ],
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/dlstack/CS6910%20ASSIGNMENT%201/runs/1vlj1zdx?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "metadata": {
        "id": "uvyRhFxTD-1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "(X, y), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Split the X_train into a training set and validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "M = X_train.shape[0]\n",
        "\n",
        "# Number of validation samples\n",
        "Mval = X_val.shape[0]\n",
        "\n",
        "# Number of test examples\n",
        "Mtest = X_test.shape[0]\n",
        "\n",
        "# Number of features in the dataset\n",
        "num_features = 784\n",
        "\n",
        "# Number of classes\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "# One hot encoding for class labels\n",
        "y_train_one_hot = np.zeros((10, M))\n",
        "y_train_one_hot[y_train, np.array(list(range(M)))] = 1\n",
        "y_train_one_hot = y_train_one_hot.T\n",
        "\n",
        "y_val_one_hot = np.zeros((10, Mval))\n",
        "y_val_one_hot[y_val, np.array(list(range(Mval)))] = 1\n",
        "y_val_one_hot = y_val_one_hot.T\n",
        "\n",
        "y_test_one_hot = np.zeros((10, Mtest))\n",
        "y_test_one_hot[y_test, np.array(list(range(Mtest)))] = 1\n",
        "y_test_one_hot = y_test_one_hot.T\n",
        "example_indices = [list(y_train).index(i) for i in range(num_classes)]\n",
        "\n",
        "# example_images is a list containing one sample image per class, example_captions stores the corresponsing captions\n",
        "example_images = []\n",
        "example_captions = []\n",
        "for index in example_indices:\n",
        "    example_images.append(X_train[index])\n",
        "    example_captions.append(class_names[y_train[index]])\n",
        "\n",
        "# Log one sample image of each class to wandb\n",
        "wandb.log({\"Sample Image from each class\": [wandb.Image(image, caption=caption) for image, caption in zip(example_images, example_captions)]})"
      ],
      "metadata": {
        "id": "o0dVViG8YLhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppzZZcjxUyKY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed51ebd4-8fb5-496f-d7d3-f27f636c6e4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#importing datasets\n",
        "from keras.datasets import fashion_mnist\n",
        "(x_train,y_train), (x_test,y_test) = fashion_mnist.load_data()\n",
        "x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size=0.1,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbQKM9EaWvrf"
      },
      "outputs": [],
      "source": [
        "X_train = np.float128(x_train.reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2]).T)\n",
        "Y_train = np.float128(pd.get_dummies(y_train).T)\n",
        "\n",
        "X_test = np.float128(x_test.reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2]).T)\n",
        "Y_test = np.float128(pd.get_dummies(y_test).T)\n",
        "\n",
        "X_val = np.float128(x_val.reshape(x_val.shape[0],x_val.shape[1]*x_val.shape[2]).T)\n",
        "Y_val = np.float128(pd.get_dummies(y_val).T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mx5Y89VXIjH"
      },
      "outputs": [],
      "source": [
        "class FeedForwardNN:\n",
        "  def __init__(self,config=None,epochs=5,hidden_layers=[64,64,64],weight_decay=0,learning_rate=1e-3,optimizer='sgd',batch_size=16,weight_initialization='random',activations='sigmoid',loss_function='cross-entropy',output_function='softmax',gamma=0.9,beta=0.9,beta1=0.9,beta2=0.999,eps=1e-8):\n",
        "    if config is not None:\n",
        "      self.epochs = config[\"epochs\"]\n",
        "      self.learning_rate = config[\"learning_rate\"]\n",
        "      self.weight_decay = config[\"weight_decay\"]\n",
        "      self.optimizer = config[\"optimizer\"]\n",
        "      self.batch_size = config[\"batch_size\"]\n",
        "      self.weight_initialization = config[\"weight_initialization\"]\n",
        "      self.activations = config[\"activations\"]\n",
        "      self.hidden_layers = [config[\"hidden_layers_size\"] for x in range(config[\"no_hidden_layers\"])]\n",
        "    else:\n",
        "      self.epochs = epochs\n",
        "      self.learning_rate = learning_rate\n",
        "      self.weight_decay = weight_decay\n",
        "      self.optimizer = optimizer\n",
        "      self.batch_size = batch_size\n",
        "      self.weight_initialization = weight_initialization\n",
        "      self.activations = activations\n",
        "      self.hidden_layers = hidden_layers\n",
        "\n",
        "    self.loss_function = loss_function\n",
        "    self.output_function = output_function\n",
        "    self.gamma = gamma\n",
        "    self.beta = beta\n",
        "    self.beta1 = beta1\n",
        "    self.beta2 = beta2\n",
        "    self.eps = eps\n",
        "\n",
        "    self.initialize()\n",
        "\n",
        "\n",
        "  def sigmoid(self,x):\n",
        "    return 1.0 / (1.0 + np.exp(-x))\n",
        "    \n",
        "  def tanh(self,x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "  def ReLu(self,x):\n",
        "    p = np.vectorize(lambda a: max(0,a))\n",
        "    return p(x)\n",
        "\n",
        "  def d_sigmoid(self,x):\n",
        "    return self.sigmoid(x)*(1.0 - self.sigmoid(x))\n",
        "  def d_tanh(self,x):\n",
        "    return 1.0 - self.tanh(x)*self.tanh(x) \n",
        "\n",
        "  def d_ReLu(self,x):\n",
        "    return 1*(x>0)\n",
        "\n",
        "  def activation(self,x,n='sigmoid'):\n",
        "    if n == 'sigmoid':\n",
        "      return self.sigmoid(x)\n",
        "    elif n == 'tanh':\n",
        "      return self.tanh(x)\n",
        "    elif n == 'ReLu':\n",
        "      return self.ReLu(x)\n",
        "\n",
        "  def d_activation(self,x,n='sigmoid'):\n",
        "    if n == 'sigmoid':\n",
        "      return self.d_sigmoid(x)\n",
        "    elif n == 'tanh':\n",
        "      return self.d_tanh(x)\n",
        "    elif n=='ReLu':\n",
        "      return self.d_ReLu(x)\n",
        "\n",
        "\n",
        "  def softmax(self,x):\n",
        "    e = np.exp(x)\n",
        "    return e / np.sum(e,axis=0)\n",
        "\n",
        "  def output(self,x,n='softmax'):\n",
        "    if n == 'softmax':\n",
        "      return self.softmax(x)\n",
        "\n",
        "  def cross_error(self,Y,inputs):\n",
        "    Y_hat = inputs[1][-1]\n",
        "    return -1*np.sum(Y*(np.log(Y_hat)))\n",
        "\n",
        "  def squared_error(self,Y,inputs):\n",
        "    Y_hat = inputs[1][-1]\n",
        "    return (1/2)*np.sum((Y_hat - Y)**2)\n",
        "\n",
        "  def squared_error_val(self,Y,inputs):\n",
        "    W,B = self.theta\n",
        "    Y_hat = inputs[1][-1]\n",
        "    m = Y.shape[1]\n",
        "    return (1/(2*m))*np.sum((Y_hat - Y)**2) + (self.lambd/(2*m))*(self.frobenius(W**2) + self.frobenius(B**2))\n",
        "\n",
        "  def error(self,Y,inputs,n='cross-entropy'):\n",
        "    if n == 'cross-entropy':\n",
        "      return self.cross_error(Y,inputs)\n",
        "    elif n == 'squared-error':\n",
        "      return self.squared_error(Y,inputs) \n",
        "  \n",
        "  def cross_error_val(self,Y,inputs):\n",
        "    W,B = self.theta\n",
        "    Y_hat = inputs[1][-1]\n",
        "    m = Y.shape[1]\n",
        "    return (-1/m)*np.sum(Y*(np.log(Y_hat))) + (self.lambd/(2*m))*(self.frobenius(W**2) + self.frobenius(B**2))\n",
        "\n",
        "  def val_error(self,Y,inputs,n='cross-entropy'):\n",
        "    if n == 'cross-entropy':\n",
        "      return self.cross_error_val(Y,inputs)\n",
        "    if n == 'squared-error':\n",
        "      return self.squared_error_val(Y,inputs)\n",
        "\n",
        "  def random_initialize_parameters(self,n,layers):\n",
        "    L = len(layers)\n",
        "    biases = []\n",
        "    weights = []\n",
        "    for i in range(L):\n",
        "      bias = np.float128(np.zeros((layers[i],1)))\n",
        "      if i == 0:\n",
        "        weight = np.float128(np.random.randn(layers[i],n))\n",
        "      else:\n",
        "        weight = np.float128(np.random.randn(layers[i],layers[i-1]))\n",
        "      biases.append(bias)\n",
        "      weights.append(weight)\n",
        "    return (np.array(weights),np.array(biases))\n",
        "  \n",
        "  def Xavier_initialize_parameters(self,n,layers):\n",
        "     L=len(layers)\n",
        "     biases = []\n",
        "     weights = []\n",
        "     for i in range(L):\n",
        "       bias=np.float128(np.zeros((layers[i], 1)))\n",
        "       if i==0:\n",
        "         weight=np.float128(np.random.randn(layers[i],n))\n",
        "       else:\n",
        "         weight = np.float128(np.random.randn(layers[i],layers[i - 1]) * np.sqrt(1 / layers[i - 1]))\n",
        "       biases.append(bias)\n",
        "       weights.append(weight)\n",
        "\n",
        "     return (np.array(weights),np.array(biases))\n",
        "\n",
        "\n",
        "\n",
        "  def initialize_parameters(self,n,layers,t):\n",
        "    if t == 'random':\n",
        "      return self.random_initialize_parameters(n,layers)\n",
        "    elif t == 'Xavier':\n",
        "      return self.Xavier_initialize_parameters(n,layers)\n",
        "  \n",
        "  def update_theta(self,theta,d_theta,learning_rate):\n",
        "    weights, biases = theta\n",
        "    d_weights,d_biases = d_theta\n",
        "    weights = (1 - self.weight_decay)*weights - learning_rate*d_weights\n",
        "    biases = (1 - self.weight_decay)*biases - learning_rate*d_biases\n",
        "    return (weights,biases)\n",
        "\n",
        "  def update_theta_momentum(self,theta,d_theta,learning_rate,gamma,prev_weight,prev_bias):\n",
        "    weights, biases = theta\n",
        "    d_weights,d_biases = d_theta\n",
        "    v_weight=gamma*prev_weight+learning_rate*d_weights\n",
        "    v_bias=gamma*prev_bias+learning_rate*d_biases\n",
        "    weights = (1 - self.weight_decay)*weights - v_weight\n",
        "    biases = (1 - self.weight_decay)*biases - v_bias\n",
        "    return (weights,biases,v_weight,v_bias) \n",
        "\n",
        "  def update_theta_nestrov(self,theta,d_theta,learning_rate,gamma,prev_weight,prev_bias):\n",
        "    weights, biases = theta\n",
        "    d_weights,d_biases = d_theta\n",
        "    v_weight=gamma*prev_weight+learning_rate*d_weights\n",
        "    v_bias=gamma*prev_bias+learning_rate*d_biases\n",
        "    weights = (1 - self.weight_decay)*weights - v_weight\n",
        "    biases = (1 - self.weight_decay)*biases - v_bias\n",
        "    return (weights,biases,v_weight,v_bias)\n",
        "\n",
        "  def update_theta_rms_prop(self,theta,d_theta,d_theta2,prev_weights2,prev_biases2,learning_rate,beta,eps):\n",
        "    weights, biases = theta\n",
        "    d_weights,d_biases = d_theta\n",
        "    d_weights2,d_biases2 = d_theta2\n",
        "\n",
        "    prev_weights2=beta*prev_weights2 + (1-beta)*d_weights2\n",
        "    prev_biases2=beta*prev_biases2 + (1-beta)*d_biases2\n",
        "\n",
        "    W_ = learning_rate/((prev_weights2 + eps)**0.5)\n",
        "    B_ = learning_rate/((prev_biases2 + eps)**0.5)\n",
        "\n",
        "    weights = (1 - self.weight_decay)*weights - W_*d_weights\n",
        "    biases = (1 - self.weight_decay)*biases - B_*d_biases\n",
        "  \n",
        "    theta = (np.array(weights),np.array(biases))\n",
        "    return (theta,prev_weights2,prev_biases2)\n",
        "\n",
        "  def update_theta_adam(self,theta,d_theta,d_theta2,prev_weights,prev_bias,prev_weights2,prev_biases2,learning_rate,beta1,beta2,eps,t):\n",
        "    weights, biases = theta\n",
        "    d_weights,d_biases = d_theta\n",
        "    d_weights2,d_biases2 = d_theta2\n",
        "\n",
        "    prev_weights = beta1*prev_weights + (1-beta1)*d_weights\n",
        "    prev_bias = beta1*prev_bias + (1-beta1)*d_biases\n",
        "\n",
        "    prev_weights2=beta2*prev_weights2 + (1-beta2)*d_weights2\n",
        "    prev_biases2=beta2*prev_biases2 + (1-beta2)*d_biases2\n",
        "\n",
        "    M_W = prev_weights/(1-(beta1**t))\n",
        "    M_B = prev_bias/(1-(beta1**t))\n",
        "\n",
        "    V_W = prev_weights2/(1-(beta2**t))\n",
        "    V_B = prev_biases2/(1-(beta2**t))\n",
        "\n",
        "    V_W = learning_rate/((V_W**0.5) + eps)\n",
        "    V_B = learning_rate/((V_B **0.5) + eps)\n",
        "\n",
        "    weights = (1 - self.weight_decay)*weights - V_W*M_W\n",
        "    biases = (1 - self.weight_decay)*biases - V_B*M_B\n",
        "\n",
        "    theta = (np.array(weights),np.array(biases))\n",
        "    return (theta,prev_weights,prev_bias,prev_weights2,prev_biases2)\n",
        "  \n",
        "  def update_theta_nadam(self,theta,d_theta,d_theta2,prev_weights,prev_bias,prev_weights2,prev_biases2,learning_rate,beta1,beta2,eps,t):\n",
        "    weights, biases = theta\n",
        "    d_weights,d_biases = d_theta\n",
        "    d_weights2,d_biases2 = d_theta2\n",
        "\n",
        "    prev_weights = beta1*prev_weights + (1-beta1)*d_weights\n",
        "    prev_bias = beta1*prev_bias + (1-beta1)*d_biases\n",
        "\n",
        "    prev_weights2=beta2*prev_weights2 + (1-beta2)*d_weights2\n",
        "    prev_biases2=beta2*prev_biases2 + (1-beta2)*d_biases2\n",
        "\n",
        "    beta_t = 1-(beta1**t)\n",
        "    beta2_t = 1-(beta2**t)\n",
        "    M_W = beta1*prev_weights/beta_t + ((1-beta1)/beta_t)*d_weights\n",
        "    M_B = beta1*prev_bias/beta_t + ((1-beta1)/beta_t)*d_biases\n",
        "\n",
        "    V_W = prev_weights2/beta2_t\n",
        "    V_B = prev_biases2/beta2_t\n",
        "\n",
        "    V_W = learning_rate/((V_W**0.5) + eps)\n",
        "    V_B = learning_rate/((V_B **0.5) + eps)\n",
        "    \n",
        "    weights = (1 - self.weight_decay)*weights - V_W*M_W\n",
        "    biases = (1 - self.weight_decay)*biases - V_B*M_B\n",
        "\n",
        "    theta = (np.array(weights),np.array(biases))\n",
        "    return (theta,prev_weights,prev_bias,prev_weights2,prev_biases2)\n",
        "  \n",
        "  def frobenius(self,X):\n",
        "    s=0\n",
        "    for x in X:\n",
        "      s += np.sum(x)\n",
        "    return s\n",
        "  def feedforward(self,X,theta,L):\n",
        "    H = X\n",
        "    weights ,biases = theta\n",
        "    activations = []\n",
        "    pre_activations = []\n",
        "    for k in range(L-1):\n",
        "      A = biases[k] + (weights[k] @ H)\n",
        "      H = self.activation(A,self.activations)\n",
        "      pre_activations.append(A)\n",
        "      activations.append(H)\n",
        "    AL = biases[L-1] + (weights[L-1] @ H)\n",
        "    Y_hat = self.output(AL,self.output_function)\n",
        "    pre_activations.append(AL)\n",
        "    activations.append(Y_hat)\n",
        "    return (np.array(pre_activations),np.array(activations))\n",
        "  \n",
        "  def backprop(self,X,Y,inputs,theta,batch_size,L):\n",
        "    d_biases = []\n",
        "    d_weights = []\n",
        "    pre_activations , activations = inputs\n",
        "    weights,biases = theta\n",
        "    Y_hat = activations[-1]\n",
        "    if self.loss_function == 'squared-error':\n",
        "      d_AL = Y_hat*(Y_hat - Y)*(1 - Y_hat)\n",
        "    elif self.loss_function == 'cross-entropy':\n",
        "      d_AL = Y_hat - Y\n",
        "    for k in range(L-1,-1,-1):\n",
        "      if(k == 0):\n",
        "        d_W = (1/batch_size)*(d_AL @ X.T)\n",
        "        d_B = (1/batch_size)*np.sum(d_AL,axis=1,keepdims=True)\n",
        "      else:\n",
        "        d_W = (1/batch_size)*(d_AL @ activations[k-1].T)\n",
        "        d_B = (1/batch_size)*np.sum(d_AL,axis=1,keepdims=True)\n",
        "\n",
        "        d_H = weights[k].T @ d_AL\n",
        "        d_A = d_H*self.d_activation(pre_activations[k-1],self.activations)\n",
        "        d_AL = d_A\n",
        "      d_weights.insert(0,d_W)\n",
        "      d_biases.insert(0,d_B)\n",
        "    d_theta = (np.array(d_weights),np.array(d_biases))\n",
        "    return d_theta\n",
        "\n",
        "  def backprop_rms(self,X,Y,inputs,theta,batch_size,L):\n",
        "    d_biases = []\n",
        "    d_weights = []\n",
        "    d_biases2 = []\n",
        "    d_weights2 = []\n",
        "    pre_activations , activations = inputs\n",
        "    weights,biases = theta\n",
        "    Y_hat = activations[-1]\n",
        "    if self.loss_function == 'squared-error':\n",
        "      d_AL = Y_hat*(Y_hat - Y)*(1 - Y_hat)\n",
        "    elif self.loss_function == 'cross-entropy':\n",
        "      d_AL = Y_hat - Y\n",
        "    for k in range(L-1,-1,-1):\n",
        "      if(k == 0):\n",
        "        d_W = (1/batch_size)*(d_AL @ X.T)\n",
        "        d_W2 = (1/batch_size)*(d_AL**2 @ (X.T)**2)\n",
        "        d_B = (1/batch_size)*np.sum(d_AL,axis=1,keepdims=True)\n",
        "        d_B2 = (1/batch_size)*np.sum(d_AL**2,axis=1,keepdims=True)\n",
        "      else:\n",
        "        d_W = (1/batch_size)*(d_AL @ activations[k-1].T)\n",
        "        d_W2 = (1/batch_size)*(d_AL**2 @ (activations[k-1].T)**2)\n",
        "        d_B = (1/batch_size)*np.sum(d_AL,axis=1,keepdims=True)\n",
        "        d_B2 = (1/batch_size)*np.sum(d_AL**2,axis=1,keepdims=True)\n",
        "\n",
        "        d_H = weights[k].T @ d_AL\n",
        "        d_A = d_H*self.d_activation(pre_activations[k-1],self.activations)\n",
        "        d_AL = d_A\n",
        "      d_weights.insert(0,d_W)\n",
        "      d_biases.insert(0,d_B)\n",
        "      d_weights2.insert(0,d_W2)\n",
        "      d_biases2.insert(0,d_B2)\n",
        "    d_theta = (np.array(d_weights),np.array(d_biases))\n",
        "    d_theta2 = (np.array(d_weights2),np.array(d_biases2))\n",
        "    return (d_theta,d_theta2)\n",
        "\n",
        "  def mini_batch_gradient_descent(self,X,Y,theta,learning_rate,batch_size,L):\n",
        "    m = X.shape[1]\n",
        "    # print(weights[0].shape,L)\n",
        "    err = 0\n",
        "    for i in range(0,m//batch_size):\n",
        "      start = i*batch_size\n",
        "      stop = (i+1)*batch_size\n",
        "      inputs = self.feedforward(X[:,start:stop],theta,L)\n",
        "      W,B = theta\n",
        "      err += self.error(Y[:,start:stop],inputs,self.loss_function) + (self.lambd/2)*(self.frobenius(W**2) + self.frobenius(B**2))\n",
        "      d_theta = self.backprop(X[:,start:stop],Y[:,start:stop],inputs,theta,batch_size,L)\n",
        "      theta = self.update_theta(theta,d_theta,learning_rate)\n",
        "    if(m % batch_size != 0):\n",
        "      start = i*batch_size\n",
        "\n",
        "      inputs = self.feedforward(X[:,start:],theta,L)\n",
        "      d_theta = self.backprop(X[:,start:],Y[:,start:],inputs,theta,m%batch_size,L)\n",
        "\n",
        "      theta = self.update_theta(theta,d_theta,learning_rate)\n",
        "      W,B = theta\n",
        "      err += self.error(Y[:,start:],inputs,self.loss_function) + (self.lambd/2)*(self.frobenius(W**2) + self.frobenius(B**2))\n",
        "    return (theta,err/m)\n",
        "  \n",
        "  def mini_batch_gradient_descent_momentum(self,X,Y,theta,learning_rate,batch_size,gamma,L):\n",
        "    m = X.shape[1]\n",
        "    prev_weights,prev_bias=0,0\n",
        "    # print(weights[0].shape,L)\n",
        "    err = 0\n",
        "    for i in range(0,m//batch_size):\n",
        "      start = i*batch_size\n",
        "      stop = (i+1)*batch_size\n",
        "      inputs = self.feedforward(X[:,start:stop],theta,L)\n",
        "      W,B = theta\n",
        "      err += self.error(Y[:,start:stop],inputs,self.loss_function) + (self.lambd/2)*(self.frobenius(W**2) + self.frobenius(B**2))\n",
        "      d_theta = self.backprop(X[:,start:stop],Y[:,start:stop],inputs,theta,batch_size,L)\n",
        "      weights,biases,prev_weights,prev_bias= self.update_theta_momentum(theta,d_theta,learning_rate,gamma,prev_weights,prev_bias)\n",
        "      theta=weights,biases\n",
        "    if(m % batch_size != 0):\n",
        "      start = i*batch_size\n",
        "\n",
        "      inputs = self.feedforward(X[:,start:],theta,L)\n",
        "      d_theta = self.backprop(X[:,start:],Y[:,start:],inputs,theta,m%batch_size,L)\n",
        "\n",
        "      weights,biases,prev_weights,prev_bias= self.update_theta_momentum(theta,d_theta,learning_rate,gamma,prev_weights,prev_bias)\n",
        "      theta=weights,biases\n",
        "      err+= self.error(Y[:,start:],inputs,self.loss_function) + (self.lambd/2)*(self.frobenius(weights**2) + self.frobenius(biases**2))\n",
        "    return (theta,err/m)\n",
        "\n",
        "  def mini_batch_gradient_descent_nestrov(self,X,Y,theta,learning_rate,batch_size,gamma,L):\n",
        "    m = X.shape[1]\n",
        "    prev_weights,prev_bias=0,0\n",
        "    weights,biases=theta\n",
        "    \n",
        "    # print(weights[0].shape,L)\n",
        "    err = 0\n",
        "    for i in range(0,m//batch_size):\n",
        "      start = i*batch_size\n",
        "      stop = (i+1)*batch_size\n",
        "      inputs = self.feedforward(X[:,start:stop],theta,L)\n",
        "      W,B = theta\n",
        "      err += self.error(Y[:,start:stop],inputs,self.loss_function)+ (self.lambd/2)*(self.frobenius(W**2) + self.frobenius(B**2))\n",
        "      v_weight=gamma*prev_weights\n",
        "      v_biases=gamma*prev_bias\n",
        "      theta2=weights-v_weight,biases-v_biases\n",
        "      d_theta = self.backprop(X[:,start:stop],Y[:,start:stop],inputs,theta2,batch_size,L)\n",
        "      weights,biases,prev_weights,prev_bias= self.update_theta_nestrov(theta,d_theta,learning_rate,gamma,prev_weights,prev_bias)\n",
        "      theta=weights,biases\n",
        "    if(m % batch_size != 0):\n",
        "      \n",
        "      start = i*batch_size\n",
        "\n",
        "      inputs = self.feedforward(X[:,start:],theta,L)\n",
        "      v_weight=gamma*prev_weights\n",
        "      v_biases=gamma*prev_bias\n",
        "      theta2=weights-v_weight,biases-v_biases\n",
        "      d_theta = self.backprop(X[:,start:],Y[:,start:],inputs,theta2,m%batch_size,L)\n",
        "\n",
        "      weights,biases,prev_weights,prev_bias= self.update_theta_nestrov(theta,d_theta,learning_rate,gamma,prev_weights,prev_bias)\n",
        "      theta=weights,biases\n",
        "      err+= self.error(Y[:,start:],inputs,self.loss_function) + (self.lambd/2)*(self.frobenius(weights**2) + self.frobenius(biases**2))\n",
        "    return (theta,err/m)\n",
        "  \n",
        "  \n",
        "  def rms_prop(self,X,Y,theta,learning_rate,beta,eps,batch_size,L):\n",
        "    m = X.shape[1]\n",
        "    # print(weights[0].shape,L)\n",
        "    err = 0\n",
        "    prev_weights2,prev_biases2 = 0,0\n",
        "    for i in range(0,m//batch_size):\n",
        "      start = i*batch_size\n",
        "      stop = (i+1)*batch_size\n",
        "      inputs = self.feedforward(X[:,start:stop],theta,L)\n",
        "      W,B = theta\n",
        "      err += self.error(Y[:,start:stop],inputs,self.loss_function) + (self.lambd/2)*(self.frobenius(W**2) + self.frobenius(B**2))\n",
        "      d_theta,d_theta2 = self.backprop_rms(X[:,start:stop],Y[:,start:stop],inputs,theta,batch_size,L)\n",
        "      theta,prev_weights2,prev_biases2 = self.update_theta_rms_prop(theta,d_theta,d_theta2,prev_weights2,prev_biases2,learning_rate,beta,eps)\n",
        "    if(m % batch_size != 0):\n",
        "      start = i*batch_size\n",
        "\n",
        "      inputs = self.feedforward(X[:,start:],theta,L)\n",
        "      d_theta,d_theta2 = self.backprop_rms(X[:,start:],Y[:,start:],inputs,theta,batch_size,L)\n",
        "    \n",
        "      theta,prev_weights2,prev_biases2 = self.update_theta_rms_prop(theta,d_theta,d_theta2,prev_weights2,prev_biases2,learning_rate,beta,eps)\n",
        "      W,B = theta\n",
        "      err+= self.error(Y[:,start:],inputs,self.loss_function) +  (self.lambd/2)*(self.frobenius(W**2) + self.frobenius(B**2))\n",
        "    return (theta,err/m)\n",
        "    \n",
        "  def rms_prop2(self,X,Y,theta,learning_rate,beta,eps,batch_size,L):\n",
        "    m = X.shape[1]\n",
        "    # print(weights[0].shape,L)\n",
        "    err = 0\n",
        "    prev_weights2,prev_biases2 = 0,0\n",
        "    for i in range(0,m//batch_size):\n",
        "      start = i*batch_size\n",
        "      stop = (i+1)*batch_size\n",
        "      inputs = self.feedforward(X[:,start:stop],theta,L)\n",
        "      W,B = theta\n",
        "      err += self.error(Y[:,start:stop],inputs,self.loss_function) + (self.lambd/2)*(self.frobenius(W**2) + self.frobenius(B**2))\n",
        "      d_theta = self.backprop(X[:,start:stop],Y[:,start:stop],inputs,theta,batch_size,L)\n",
        "      d_weights,d_biases = d_theta\n",
        "      d_theta2 = (batch_size*(d_weights**2),batch_size*(d_biases**2))\n",
        "      theta,prev_weights2,prev_biases2 = self.update_theta_rms_prop(theta,d_theta,d_theta2,prev_weights2,prev_biases2,learning_rate,beta,eps)\n",
        "    if(m % batch_size != 0):\n",
        "      start = i*batch_size\n",
        "\n",
        "      inputs = self.feedforward(X[:,start:],theta,L)\n",
        "      d_theta = self.backprop(X[:,start:],Y[:,start:],inputs,theta,batch_size,L)\n",
        "      d_weights,d_biases = d_theta\n",
        "      d_theta2 = (batch_size*d_weights**2,batch_size*d_biases**2)\n",
        "    \n",
        "      theta,prev_weights2,prev_biases2 = self.update_theta_rms_prop(theta,d_theta,d_theta2,prev_weights2,prev_biases2,learning_rate,beta,eps)\n",
        "      W,B = theta\n",
        "      err+= self.error(Y[:,start:],inputs,self.loss_function) + (self.lambd/2)*(self.frobenius(W**2) + self.frobenius(B**2))\n",
        "    return (theta,err/m)\n",
        "\n",
        "  def adam(self,X,Y,theta,learning_rate,beta1,beta2,eps,batch_size,L):\n",
        "    m = X.shape[1]\n",
        "    # print(weights[0].shape,L)\n",
        "    err = 0\n",
        "    prev_weights2,prev_biases2,prev_weights,prev_bias = 0,0,0,0\n",
        "    for i in range(0,m//batch_size):\n",
        "      start = i*batch_size\n",
        "      stop = (i+1)*batch_size\n",
        "      inputs = self.feedforward(X[:,start:stop],theta,L)\n",
        "      W,B = theta\n",
        "      err += self.error(Y[:,start:stop],inputs,self.loss_function) + (self.lambd/2)*(self.frobenius(W**2) + self.frobenius(B**2))\n",
        "      d_theta,d_theta2 = self.backprop_rms(X[:,start:stop],Y[:,start:stop],inputs,theta,batch_size,L)\n",
        "      theta,prev_weights,prev_bias,prev_weights2,prev_biases2 = self.update_theta_adam(theta,d_theta,d_theta2,prev_weights,prev_bias,prev_weights2,prev_biases2,learning_rate,beta1,beta2,eps,i+1)\n",
        "    if(m % batch_size != 0):\n",
        "      start = i*batch_size\n",
        "\n",
        "      inputs = self.feedforward(X[:,start:],theta,L)\n",
        "      d_theta,d_theta2 = self.backprop_rms(X[:,start:],Y[:,start:],inputs,theta,batch_size,L)\n",
        "    \n",
        "      theta,prev_weights,prev_bias,prev_weights2,prev_biases2 = self.update_theta_adam(theta,d_theta,d_theta2,prev_weights,prev_bias,prev_weights2,prev_biases2,learning_rate,beta1,beta2,eps,i+1)\n",
        "      W,B = theta\n",
        "      err+= self.error(Y[:,start:],inputs,self.loss_function) + (self.lambd/2)*(self.frobenius(W**2) + self.frobenius(B**2))\n",
        "    return (theta,err/m)\n",
        "\n",
        "  def nadam(self,X,Y,theta,learning_rate,beta1,beta2,eps,batch_size,L):\n",
        "    m = X.shape[1]\n",
        "    # print(weights[0].shape,L)\n",
        "    err = 0\n",
        "    weights,bias=theta\n",
        "    prev_weights2,prev_biases2,prev_weights,prev_bias = 0,0,0,0\n",
        "    \n",
        "    for i in range(0,m//batch_size):\n",
        "      \n",
        "      start = i*batch_size\n",
        "      stop = (i+1)*batch_size\n",
        "      inputs = self.feedforward(X[:,start:stop],theta,L)\n",
        "      W,B = theta\n",
        "      err += self.error(Y[:,start:stop],inputs,self.loss_function) + (self.lambd/2)*(self.frobenius(W**2) + self.frobenius(B**2))\n",
        "      d_theta,d_theta2 = self.backprop_rms(X[:,start:stop],Y[:,start:stop],inputs,theta,batch_size,L)\n",
        "      theta,prev_weights,prev_bias,prev_weights2,prev_biases2 = self.update_theta_nadam(theta,d_theta,d_theta2,prev_weights,prev_bias,prev_weights2,prev_biases2,learning_rate,beta1,beta2,eps,i+1)\n",
        "   \n",
        "    if(m % batch_size != 0):\n",
        "      start = i*batch_size\n",
        "\n",
        "      inputs = self.feedforward(X[:,start:],theta,L)\n",
        "      d_theta,d_theta2 = self.backprop_rms(X[:,start:],Y[:,start:],inputs,theta,batch_size,L)\n",
        "    \n",
        "      theta,prev_weights,prev_bias,prev_weights2,prev_biases2 = self.update_theta_nadam(theta,d_theta,d_theta2,prev_weights,prev_bias,prev_weights2,prev_biases2,learning_rate,beta1,beta2,eps,i+1)\n",
        "      W,B = theta\n",
        "      err+= self.error(Y[:,start:],inputs,self.loss_function) + (self.lambd/2)*(self.frobenius(W**2) + self.frobenius(B**2))\n",
        "    return (theta,err/m)\n",
        "\n",
        "  def optimizations(self,theta,L):\n",
        "    if self.optimizer == 'sgd':\n",
        "      return self.mini_batch_gradient_descent(X_train,Y_train,theta,self.learning_rate,1,L)\n",
        "    elif self.optimizer == 'momentum':\n",
        "      return self.mini_batch_gradient_descent_momentum(X_train,Y_train,theta,self.learning_rate,self.batch_size,self.gamma,L)\n",
        "    elif self.optimizer == 'nesterov':\n",
        "      return self.mini_batch_gradient_descent_nestrov(X_train,Y_train,theta,self.learning_rate,self.batch_size,self.gamma,L)\n",
        "    elif self.optimizer == 'rmsprop':\n",
        "      return self.rms_prop(X_train,Y_train,theta,self.learning_rate,self.beta,self.eps,self.batch_size,L)\n",
        "    elif self.optimizer == 'adam':\n",
        "      return self.adam(X_train,Y_train,theta,self.learning_rate,self.beta1,self.beta2,self.eps,self.batch_size,L)\n",
        "    elif self.optimizer == 'nadam':\n",
        "      return self.nadam(X_train,Y_train,theta,self.learning_rate,self.beta1,self.beta2,self.eps,self.batch_size,L)\n",
        "      \n",
        "  # def model(self):\n",
        "  #   layers = self.hidden_layers + [self.Y.shape[0]]\n",
        "  #   theta = self.initialize_parameters(self.X.shape[0],layers,self.weight_initialization)\n",
        "  #   self.lambd = self.weight_decay/self.learning_rate\n",
        "  #   L = len(layers)\n",
        "  #   error = []\n",
        "  #   for i in range(self.epochs):\n",
        "  #     theta,err = self.optimizations(theta,L)\n",
        "  #     error.append(err)\n",
        "  #   self.theta = theta\n",
        "  #   return error\n",
        "\n",
        "  def initialize(self):\n",
        "    layers = self.hidden_layers + [Y_train.shape[0]]\n",
        "    self.theta = self.initialize_parameters(X_train.shape[0],layers,self.weight_initialization)\n",
        "    self.lambd = self.weight_decay/self.learning_rate\n",
        "    self.L = len(layers)\n",
        "  \n",
        "\n",
        "  def fit(self):\n",
        "    self.theta,train_loss = self.optimizations(self.theta,self.L)\n",
        "\n",
        "    outputs_train = self.feedforward(X_train,self.theta,self.L)\n",
        "    Y_pred_train = np.argmax(outputs_train[1][-1],0)\n",
        "    Y_true_train = np.argmax(Y_train,0)\n",
        "    train_acc = accuracy_score(Y_true_train,Y_pred_train)\n",
        "\n",
        "    outputs_val = self.feedforward(X_val,self.theta,self.L)\n",
        "    val_loss = self.val_error(Y_val,outputs_val,self.loss_function)\n",
        "    Y_pred_val = np.argmax(outputs_val[1][-1],0)\n",
        "    Y_true_val = np.argmax(Y_val,0)\n",
        "    val_acc = accuracy_score(Y_true_val,Y_pred_val)\n",
        "    \n",
        "    return train_acc,train_loss,val_acc,val_loss\n",
        "    \n",
        "    \n",
        "  def predict(self,X_test):\n",
        "    L = len(self.hidden_layers) + 1\n",
        "    outputs = self.feedforward(X_test,self.theta,L)\n",
        "    Y_pred = np.argmax(outputs[1][-1],0)\n",
        "    return Y_pred"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config_ReLU = {\n",
        "  \"name\" : \"best-sweep-1\",\n",
        "  \"method\" : \"random\",\n",
        "  \"metric\" : {\n",
        "      \"name\" : \"accuracy\",\n",
        "      \"goal\" : \"maximize\"\n",
        "  },\n",
        "  \"parameters\" : {\n",
        "    \"epochs\" : {\n",
        "      \"values\" : [5,10]\n",
        "    },\n",
        "    \"learning_rate\" :{\n",
        "      \"values\" : [1e-3,1e-4]\n",
        "    },\n",
        "    \"no_hidden_layers\":{\n",
        "        \"values\" : [3,4,5]\n",
        "    },\n",
        "    \"hidden_layers_size\":{\n",
        "        \"values\" : [32,64,128]\n",
        "    },\n",
        "    \"weight_decay\":{\n",
        "      \"values\": [0,0.0005,0.00005]  \n",
        "    },\n",
        "    \"optimizer\":{\n",
        "        \"values\": [\"rmsprop\",\"adam\",\"nadam\"]\n",
        "    },\n",
        "    \"batch_size\":{\n",
        "        \"values\":[16,32,64]\n",
        "    },\n",
        "    \"weight_initialization\":{\n",
        "        \"value\": \"Xavier\"\n",
        "    },\n",
        "    \"activations\":{\n",
        "        \"value\": \"ReLu\"\n",
        "    }\n",
        "  }\n",
        "}\n",
        "sweep_config_Others = {\n",
        "  \"name\" : \"best-sweep-2-squared-error\",\n",
        "  \"method\" : \"random\",\n",
        "  \"metric\" : {\n",
        "      \"name\" : \"accuracy\",\n",
        "      \"goal\" : \"maximize\"\n",
        "  },\n",
        "  \"parameters\" : {\n",
        "    \"epochs\" : {\n",
        "      \"values\" : [5,10]\n",
        "    },\n",
        "    \"learning_rate\" :{\n",
        "      \"values\" : [1e-3,1e-4]\n",
        "    },\n",
        "    \"no_hidden_layers\":{\n",
        "        \"values\" : [3,4,5]\n",
        "    },\n",
        "    \"hidden_layers_size\":{\n",
        "        \"values\" : [32,64,128]\n",
        "    },\n",
        "    \"weight_decay\":{\n",
        "      \"values\": [0,0.00005,0.0005,0.5]  \n",
        "    },\n",
        "    \"optimizer\":{\n",
        "        \"values\": [\"sgd\",\"momentum\",\"nesterov\",\"rms_prop\",\"adam\",\"nadam\"]\n",
        "    },\n",
        "    \"batch_size\":{\n",
        "        \"values\":[16,32,64]\n",
        "    },\n",
        "    \"weight_initialization\":{\n",
        "        \"values\":[\"random\",\"Xavier\"]\n",
        "    },\n",
        "    \"activations\":{\n",
        "        \"values\":[\"sigmoid\",\"tanh\"]\n",
        "    }\n",
        "  }\n",
        "}\n",
        "sweep_config_ReLU2 = {\n",
        "  \"name\" : \"best-sweep-3\",\n",
        "  \"method\" : \"random\",\n",
        "  \"metric\" : {\n",
        "      \"name\" : \"accuracy\",\n",
        "      \"goal\" : \"maximize\"\n",
        "  },\n",
        "  \"parameters\" : {\n",
        "    \"epochs\" : {\n",
        "      \"values\" : [10]\n",
        "    },\n",
        "    \"learning_rate\" :{\n",
        "      \"values\" : [1e-3]\n",
        "    },\n",
        "    \"no_hidden_layers\":{\n",
        "        \"values\" : [5]\n",
        "    },\n",
        "    \"hidden_layers_size\":{\n",
        "        \"values\" : [128]\n",
        "    },\n",
        "    \"weight_decay\":{\n",
        "      \"values\": [0]  \n",
        "    },\n",
        "    \"optimizer\":{\n",
        "        \"values\": [\"adam\",\"nadam\",\"rmsprop\"]\n",
        "    },\n",
        "    \"batch_size\":{\n",
        "        \"values\":[32]\n",
        "    },\n",
        "    \"weight_initialization\":{\n",
        "        \"value\": \"Xavier\"\n",
        "    },\n",
        "    \"activations\":{\n",
        "        \"value\": \"ReLu\"\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "#sweep_id = wandb.sweep(sweep_config_ReLU,project=\"CS6910 ASSIGNMENT 1\", entity=\"dlstack\")\n",
        "#sweep_id2 = wandb.sweep(sweep_config_Others,project=\"CS6910 ASSIGNMENT 1\", entity=\"dlstack\")\n",
        "sweep_id2 = wandb.sweep(sweep_config_ReLU2,project=\"CS6910 ASSIGNMENT 1\", entity=\"dlstack\")"
      ],
      "metadata": {
        "id": "a0qg6MKfC7Ek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3225c2a-00cb-498e-be43-79d7fe7dc21f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: dnmvvg4m\n",
            "Sweep URL: https://wandb.ai/dlstack/CS6910%20ASSIGNMENT%201/sweeps/dnmvvg4m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def best_model_by_accuracy(Models):\n",
        "  sorted_List = sorted(Models,key = lambda d : d['accuracy'],reverse=True)\n",
        "  best_model = sorted_List[0]['model']\n",
        "  return best_model"
      ],
      "metadata": {
        "id": "2yQzr4sw6gWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Models = []\n",
        "def train():\n",
        "    with wandb.init() as run:\n",
        "        config = wandb.config\n",
        "        # print(config)\n",
        "        model = FeedForwardNN(config=config)\n",
        "        train_acc,train_loss,val_acc,val_loss = 0,0,0,0\n",
        "        for epoch in range(config[\"epochs\"]):\n",
        "            train_acc,train_loss,val_acc,val_loss = model.fit()  # model training code here\n",
        "            metrics = {\n",
        "            \"accuracy\":train_acc,\n",
        "             \"loss\":train_loss,\n",
        "            \"validation_accuracy\": val_acc,\n",
        "            \"validation_loss\": val_loss,\n",
        "             \"epochs\":epoch\n",
        "             }\n",
        "            wandb.log(metrics) \n",
        "        Models.append({\n",
        "            \"accuracy\":train_acc,\n",
        "            \"loss\":train_loss,\n",
        "            \"validation_accuracy\": val_acc,\n",
        "            \"validation_loss\": val_loss,\n",
        "            \"model\":model\n",
        "        })          \n",
        "\n",
        "count = 5 # number of runs to execute\n",
        "# wandb.agent(sweep_id, function=train, count=count)\n",
        "wandb.agent(sweep_id2, function=train, count=count)\n",
        "best_model = best_model_by_accuracy(Models)\n",
        "Y_true_test = np.argmax(Y_test,0)\n",
        "Y_true_pred = best_model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4bbf8ddc71254023b48ec71e259d729c",
            "cbc39f786b4b49e2bf70a513af045d19",
            "9550502473f0408d90076e3022ff3ef0",
            "260afb2b3c8b4df7a7f62dcb9449d461",
            "583a8f382c3e4343a9cc191bfbc39e79",
            "b5bcaab48afa4d1290690744af9748e0",
            "60637f582a2b425bbfc5d34072ef16ab",
            "7db2d8abf8744538aad11622a639a27b",
            "1ab8954e95c747768af109b5d5ba7ee3",
            "9ba2f39552de4324963b465a2a25d856",
            "68207171a5b64f23874a18427f7144f5",
            "1aabdbb35d3745c9b1acd65e19cbc9cc",
            "ec4b74777bd2461a84ccb17380a1302a",
            "f46564c087f7404cb1a71c6bc8b4742c",
            "0db4e64d84354a19ab2b88a6961eb7a1",
            "4e18410d578144fcac24418866495cd7"
          ]
        },
        "id": "F-QEUNCUyUre",
        "outputId": "9a91ed4e-df2b-4410-f45a-62c8e24200f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9siosa9q with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivations: ReLu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_hidden_layers: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_initialization: Xavier\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmak109\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/dlstack/CS6910%20ASSIGNMENT%201/runs/9siosa9q\" target=\"_blank\">deft-sweep-1</a></strong> to <a href=\"https://wandb.ai/dlstack/CS6910%20ASSIGNMENT%201\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "Sweep page: <a href=\"https://wandb.ai/dlstack/CS6910%20ASSIGNMENT%201/sweeps/dnmvvg4m\" target=\"_blank\">https://wandb.ai/dlstack/CS6910%20ASSIGNMENT%201/sweeps/dnmvvg4m</a><br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:135: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 260... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4bbf8ddc71254023b48ec71e259d729c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
              "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▁▂▃▄▅▆▇██</td></tr><tr><td>epochs</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▂▁▁▁▁▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▁▁▂▃▅▆███</td></tr><tr><td>validation_loss</td><td>█▄▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
              "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.85361</td></tr><tr><td>epochs</td><td>9</td></tr><tr><td>loss</td><td>0.4472</td></tr><tr><td>validation_accuracy</td><td>0.81583</td></tr><tr><td>validation_loss</td><td>0.71246</td></tr></table>\n",
              "</div></div>\n",
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
              "<br/>Synced <strong style=\"color:#cdcd00\">deft-sweep-1</strong>: <a href=\"https://wandb.ai/dlstack/CS6910%20ASSIGNMENT%201/runs/9siosa9q\" target=\"_blank\">https://wandb.ai/dlstack/CS6910%20ASSIGNMENT%201/runs/9siosa9q</a><br/>\n",
              "Find logs at: <code>./wandb/run-20220225_065347-9siosa9q/logs</code><br/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gfkirssm with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivations: ReLu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_hidden_layers: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_initialization: Xavier\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/dlstack/CS6910%20ASSIGNMENT%201/runs/gfkirssm\" target=\"_blank\">fragrant-sweep-2</a></strong> to <a href=\"https://wandb.ai/dlstack/CS6910%20ASSIGNMENT%201\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "Sweep page: <a href=\"https://wandb.ai/dlstack/CS6910%20ASSIGNMENT%201/sweeps/dnmvvg4m\" target=\"_blank\">https://wandb.ai/dlstack/CS6910%20ASSIGNMENT%201/sweeps/dnmvvg4m</a><br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:135: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 510... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ab8954e95c747768af109b5d5ba7ee3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
              "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▂▃▄▅▅▇▇██</td></tr><tr><td>epochs</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▂▂▁▁▁▁▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▂▄▄▆▆▇▇██</td></tr><tr><td>validation_loss</td><td>█▃▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
              "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.85048</td></tr><tr><td>epochs</td><td>9</td></tr><tr><td>loss</td><td>0.43722</td></tr><tr><td>validation_accuracy</td><td>0.81267</td></tr><tr><td>validation_loss</td><td>0.59903</td></tr></table>\n",
              "</div></div>\n",
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
              "<br/>Synced <strong style=\"color:#cdcd00\">fragrant-sweep-2</strong>: <a href=\"https://wandb.ai/dlstack/CS6910%20ASSIGNMENT%201/runs/gfkirssm\" target=\"_blank\">https://wandb.ai/dlstack/CS6910%20ASSIGNMENT%201/runs/gfkirssm</a><br/>\n",
              "Find logs at: <code>./wandb/run-20220225_073310-gfkirssm/logs</code><br/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rs7dqx1y with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivations: ReLu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_hidden_layers: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_initialization: Xavier\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/dlstack/CS6910%20ASSIGNMENT%201/runs/rs7dqx1y\" target=\"_blank\">gentle-sweep-3</a></strong> to <a href=\"https://wandb.ai/dlstack/CS6910%20ASSIGNMENT%201\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "Sweep page: <a href=\"https://wandb.ai/dlstack/CS6910%20ASSIGNMENT%201/sweeps/dnmvvg4m\" target=\"_blank\">https://wandb.ai/dlstack/CS6910%20ASSIGNMENT%201/sweeps/dnmvvg4m</a><br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:135: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:260: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:319: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bern_cnf_matrix_test = confusion_matrix(Y_true_test, Y_true_pred, normalize='true')\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "ax = sns.heatmap(bern_cnf_matrix_test, annot=bern_cnf_matrix_test,xticklabels=class_names, yticklabels=class_names)\n",
        "ax.set_title(\"Confusion Matrix (Test set)\", size=16)\n",
        "ax.set_xlabel(\"Predicted Class\", size=14)\n",
        "ax.set_ylabel(\"True Class\", size=14)\n",
        "plt.savefig(\"testmatrix_best\")\n",
        "img2 = plt.imread(\"testmatrix_best.png\")\n",
        "#wandb.init(project=\"CS6910 ASSIGNMENT 1\", entity=\"dlstack\", name=\"CONFUSION_MATRIX\")\n",
        "#wandb.log({\"Confusion Matrix - Test set 3\": wandb.sklearn.plot_confusion_matrix(Y_true_test, Y_true_pred, class_names)})\n",
        "wandb.init(project=\"CS6910 ASSIGNMENT 1\", entity=\"dlstack\", name=\"Confusion matrix-best\")\n",
        "wandb.log({\"Confusion Matrix Best\": wandb.Image(img2)})\n",
        "wandb.finish()\n",
        "# wandb.sklearn.plot_confusion_matrix(Y_true_test, Y_true_pred, class_names)"
      ],
      "metadata": {
        "id": "WvMvNfWPi6qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:pass\n"
      ],
      "metadata": {
        "id": "3rrzgkPMM0Yq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of cs6910_assignment1v2.0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4bbf8ddc71254023b48ec71e259d729c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cbc39f786b4b49e2bf70a513af045d19",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9550502473f0408d90076e3022ff3ef0",
              "IPY_MODEL_260afb2b3c8b4df7a7f62dcb9449d461"
            ]
          }
        },
        "cbc39f786b4b49e2bf70a513af045d19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9550502473f0408d90076e3022ff3ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_583a8f382c3e4343a9cc191bfbc39e79",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.02MB of 0.02MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5bcaab48afa4d1290690744af9748e0"
          }
        },
        "260afb2b3c8b4df7a7f62dcb9449d461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_60637f582a2b425bbfc5d34072ef16ab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7db2d8abf8744538aad11622a639a27b"
          }
        },
        "583a8f382c3e4343a9cc191bfbc39e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5bcaab48afa4d1290690744af9748e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60637f582a2b425bbfc5d34072ef16ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7db2d8abf8744538aad11622a639a27b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ab8954e95c747768af109b5d5ba7ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9ba2f39552de4324963b465a2a25d856",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_68207171a5b64f23874a18427f7144f5",
              "IPY_MODEL_1aabdbb35d3745c9b1acd65e19cbc9cc"
            ]
          }
        },
        "9ba2f39552de4324963b465a2a25d856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68207171a5b64f23874a18427f7144f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_ec4b74777bd2461a84ccb17380a1302a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.02MB of 0.02MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f46564c087f7404cb1a71c6bc8b4742c"
          }
        },
        "1aabdbb35d3745c9b1acd65e19cbc9cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0db4e64d84354a19ab2b88a6961eb7a1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e18410d578144fcac24418866495cd7"
          }
        },
        "ec4b74777bd2461a84ccb17380a1302a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f46564c087f7404cb1a71c6bc8b4742c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0db4e64d84354a19ab2b88a6961eb7a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e18410d578144fcac24418866495cd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}